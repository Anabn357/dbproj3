{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1195 entries, 0 to 1194\n",
      "Data columns (total 24 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       1195 non-null   int64  \n",
      " 1   Name             1195 non-null   int64  \n",
      " 2   Platform         1195 non-null   int64  \n",
      " 3   Year_of_Release  1195 non-null   int64  \n",
      " 4   Genre            1195 non-null   int64  \n",
      " 5   Publisher        1195 non-null   int64  \n",
      " 6   NA_Sales         1195 non-null   float64\n",
      " 7   EU_Sales         1195 non-null   float64\n",
      " 8   JP_Sales         1195 non-null   float64\n",
      " 9   Other_Sales      1195 non-null   float64\n",
      " 10  Global_Sales     1195 non-null   float64\n",
      " 11  Critic_Score     1195 non-null   int64  \n",
      " 12  Critic_Count     1195 non-null   int64  \n",
      " 13  User_Score       1195 non-null   float64\n",
      " 14  User_Count       1195 non-null   int64  \n",
      " 15  Developer        1195 non-null   int64  \n",
      " 16  Rating           1195 non-null   int64  \n",
      " 17  PlayScore        1195 non-null   float64\n",
      " 18  GameScore        1195 non-null   float64\n",
      " 19  CriticScore      1195 non-null   float64\n",
      " 20  GlobalSellers    1195 non-null   int64  \n",
      " 21  TopSellers       1195 non-null   int64  \n",
      " 22  TopRated         1195 non-null   int64  \n",
      " 23  Critc_Count      1195 non-null   int64  \n",
      "dtypes: float64(9), int64(15)\n",
      "memory usage: 224.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Resources/whatoplay_data.csv\")\n",
    "data = pd.read_csv(\"../Resources/MLdata.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "      <th>PlayScore</th>\n",
       "      <th>GameScore</th>\n",
       "      <th>CriticScore</th>\n",
       "      <th>GlobalSellers</th>\n",
       "      <th>TopSellers</th>\n",
       "      <th>TopRated</th>\n",
       "      <th>Critc_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>7.02</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3.96</td>\n",
       "      <td>...</td>\n",
       "      <td>3994</td>\n",
       "      <td>303</td>\n",
       "      <td>2</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.34</td>\n",
       "      <td>9.24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.42</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.57</td>\n",
       "      <td>...</td>\n",
       "      <td>5234</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.56</td>\n",
       "      <td>8.44</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>...</td>\n",
       "      <td>632</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.77</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5.99</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.79</td>\n",
       "      <td>...</td>\n",
       "      <td>1094</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>8.16</td>\n",
       "      <td>7.91</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Name  Platform  Year_of_Release  Genre  Publisher  NA_Sales  \\\n",
       "0           0   323         2             2013      0         81      7.02   \n",
       "1           1   109         2             2012      8          3      4.99   \n",
       "2           2   113         2             2011      8          3      5.54   \n",
       "3           3   457         0             2011      6         56      5.03   \n",
       "4           4   108         2             2010      8          3      5.99   \n",
       "\n",
       "   EU_Sales  JP_Sales  Other_Sales  ...  User_Count  Developer  Rating  \\\n",
       "0      9.09      0.98         3.96  ...        3994        303       2   \n",
       "1      5.73      0.65         2.42  ...         922        380       2   \n",
       "2      5.73      0.49         1.57  ...        5234        184       2   \n",
       "3      4.02      2.69         0.91  ...         632        300       0   \n",
       "4      4.37      0.48         1.79  ...        1094        380       2   \n",
       "\n",
       "   PlayScore  GameScore  CriticScore  GlobalSellers  TopSellers  TopRated  \\\n",
       "0       9.29       9.34         9.24              0           1         1   \n",
       "1       7.73       7.52         7.95              3           1         0   \n",
       "2       8.00       7.56         8.44              3           1         1   \n",
       "3       9.09       9.77         8.41              3           1         1   \n",
       "4       8.16       7.91         8.41              3           1         1   \n",
       "\n",
       "   Critc_Count  \n",
       "0           46  \n",
       "1           17  \n",
       "2           35  \n",
       "3           69  \n",
       "4           54  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>...</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "      <th>PlayScore</th>\n",
       "      <th>GameScore</th>\n",
       "      <th>CriticScore</th>\n",
       "      <th>GlobalSellers</th>\n",
       "      <th>TopSellers</th>\n",
       "      <th>TopRated</th>\n",
       "      <th>Critc_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>323</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>7.02</td>\n",
       "      <td>9.09</td>\n",
       "      <td>0.98</td>\n",
       "      <td>3.96</td>\n",
       "      <td>21.04</td>\n",
       "      <td>...</td>\n",
       "      <td>3994</td>\n",
       "      <td>303</td>\n",
       "      <td>2</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.34</td>\n",
       "      <td>9.24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.65</td>\n",
       "      <td>2.42</td>\n",
       "      <td>13.79</td>\n",
       "      <td>...</td>\n",
       "      <td>922</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>7.73</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.95</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5.54</td>\n",
       "      <td>5.73</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.57</td>\n",
       "      <td>13.32</td>\n",
       "      <td>...</td>\n",
       "      <td>5234</td>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>7.56</td>\n",
       "      <td>8.44</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>2011</td>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>5.03</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.91</td>\n",
       "      <td>12.66</td>\n",
       "      <td>...</td>\n",
       "      <td>632</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>9.09</td>\n",
       "      <td>9.77</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5.99</td>\n",
       "      <td>4.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.79</td>\n",
       "      <td>12.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1094</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>8.16</td>\n",
       "      <td>7.91</td>\n",
       "      <td>8.41</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "      <td>6.02</td>\n",
       "      <td>5.66</td>\n",
       "      <td>6.38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>7.04</td>\n",
       "      <td>7.38</td>\n",
       "      <td>6.71</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>175</td>\n",
       "      <td>3</td>\n",
       "      <td>8.39</td>\n",
       "      <td>8.98</td>\n",
       "      <td>7.80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>488</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>8.61</td>\n",
       "      <td>9.34</td>\n",
       "      <td>7.87</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>481</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>412</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>7.98</td>\n",
       "      <td>8.16</td>\n",
       "      <td>7.79</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Platform  Year_of_Release  Genre  Publisher  NA_Sales  EU_Sales  \\\n",
       "0      323         2             2013      0         81      7.02      9.09   \n",
       "1      109         2             2012      8          3      4.99      5.73   \n",
       "2      113         2             2011      8          3      5.54      5.73   \n",
       "3      457         0             2011      6         56      5.03      4.02   \n",
       "4      108         2             2010      8          3      5.99      4.37   \n",
       "...    ...       ...              ...    ...        ...       ...       ...   \n",
       "1190    17         1             2008      1         10      0.00      0.01   \n",
       "1191   127         1             2007      8         17      0.00      0.01   \n",
       "1192   870         1             2012      0          3      0.01      0.00   \n",
       "1193   872         1             2009      0         58      0.00      0.01   \n",
       "1194   481         1             2014      0         42      0.00      0.01   \n",
       "\n",
       "      JP_Sales  Other_Sales  Global_Sales  ...  User_Count  Developer  Rating  \\\n",
       "0         0.98         3.96         21.04  ...        3994        303       2   \n",
       "1         0.65         2.42         13.79  ...         922        380       2   \n",
       "2         0.49         1.57         13.32  ...        5234        184       2   \n",
       "3         2.69         0.91         12.66  ...         632        300       0   \n",
       "4         0.48         1.79         12.63  ...        1094        380       2   \n",
       "...        ...          ...           ...  ...         ...        ...     ...   \n",
       "1190      0.00         0.00          0.01  ...         148        114       2   \n",
       "1191      0.00         0.00          0.01  ...         218        227       2   \n",
       "1192      0.00         0.00          0.01  ...         121        175       3   \n",
       "1193      0.00         0.00          0.01  ...         488        144       1   \n",
       "1194      0.00         0.00          0.01  ...         412        199       2   \n",
       "\n",
       "      PlayScore  GameScore  CriticScore  GlobalSellers  TopSellers  TopRated  \\\n",
       "0          9.29       9.34         9.24              0           1         1   \n",
       "1          7.73       7.52         7.95              3           1         0   \n",
       "2          8.00       7.56         8.44              3           1         1   \n",
       "3          9.09       9.77         8.41              3           1         1   \n",
       "4          8.16       7.91         8.41              3           1         1   \n",
       "...         ...        ...          ...            ...         ...       ...   \n",
       "1190       6.02       5.66         6.38              2           0         0   \n",
       "1191       7.04       7.38         6.71              2           0         0   \n",
       "1192       8.39       8.98         7.80              2           0         0   \n",
       "1193       8.61       9.34         7.87              2           0         0   \n",
       "1194       7.98       8.16         7.79              2           0         0   \n",
       "\n",
       "      Critc_Count  \n",
       "0              46  \n",
       "1              17  \n",
       "2              35  \n",
       "3              69  \n",
       "4              54  \n",
       "...           ...  \n",
       "1190           15  \n",
       "1191           21  \n",
       "1192            9  \n",
       "1193           46  \n",
       "1194           16  \n",
       "\n",
       "[1195 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['CriticScore'].values.reshape(-1, 1)\n",
    "y = data['Global_Sales'].values.reshape(-1, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.11637595745678442\n",
      "Testing Score: 0.14259418504522559\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data and calculate the scores for the training and testing data\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Residual Plot')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEICAYAAAC6fYRZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xU5b3v8c8vCQQCWDSh4gaTULVUghCRoiJVe8pma6untrtVcES3CqnF6zndr5Ya2ba6w9bTVgFvNbJBClNaXrVaT2u3VU+7W1/UKlTwhhY1F6IUISq3cEvmOX+smTBJZnKbWTPD4vt+vXhlZs2aWU/G+J1nfutZz2POOUREJJjyst0AERHxj0JeRCTAFPIiIgGmkBcRCTCFvIhIgCnkRUQCTCEvRw0ze93Mzk/y2Plm1pSm4/zBzOb043n/YmbPp6MNIjEKeck5ZlZvZvvMbI+Z/d3MHjWzoam+rnOuwjn3hzQ0sd/M7Htmdij6u31sZmvN7Ox+vE6/Pkjk6KOQl1x1sXNuKFAJnA58N8vtSaefR3+3EcDzwC/NzLLcJgkohbzkNOfc34Gn8cIeADMrNLMfmlmjmW0zsx+b2eDoYyVm9utoL/lDM/uTmeVFH6s3s+nR24Oj3xA+MrM3gM/GH9fMnJmdHHf/UTP79+jtY6PH2B59/q/NbHQ/frdDwApgJFDc+XEzm2pmL5nZzujPqdHtNcDngPuj3wju7+ux5eihkJecFg3PC4G34zbfDXwaL/hPBkYB/xZ97FtAE14v+XjgViDR3B23AydF//0TcFUfmpUHLAfKgFJgH9DnoDWzQuBfgCbn3I5Ojx0H/AZYgvcBcA/wGzMrds5VA38CbnDODXXO3dDXY8vRQyEvueoJM9sNbAE+wAtlomWNucD/cs596JzbDSwEZkafdwg4AShzzh1yzv3JJZ6g6VKgJvoaW/DCtFecc83Ouceccy3R49cA5/Xhd7vUzD6O/m5nAJck2OdLwGbn3ErnXKtzbjXwJnBxH44jopCXnHWJc24YcD7wGaAkun0EUASsj5ZkPgb+K7od4Ad4vf7fmdm7ZjY/yev/A17IxjT0tmFmVmRmD5tZg5ntAv4IDDez/F6+xBrn3HDn3Cedc//DObc+Sfs6t6kB71uLSK8p5CWnOef+G3gU+GF00w688khFNCiHO+c+ET2RiXNut3PuW865T+H1ev+3mX0hwUtvBU6Mu1/a6fEWvA+TmJFxt78FjAXOdM4dA5wb3Z7Ok6fv45WD4pUC70Vva/pY6RWFvBwJFgH/aGaVzrkI8Ahwr5l9EsDMRpnZP0VvX2RmJ0fLOruAtui/ztYA342eRB0N3Njp8Q3A5WaWb2YX0LEcMwzvg+bjaO389vT9qu2eAj5tZpebWYGZXQaMA34dfXwb8CkfjisBo5CXnOec2w78BFgQ3fQdvJLMC9FyybN4PWuAU6L39wB/Bh5MMjb++3jljzrgd8DKTo/fjPdN4GMgBDwR99giYDDet4oX8MpFaeWcawYuwvvW0Ax8G7go7gTtYuBr0dE9vT6fIEcf06IhIiLBpZ68iEiAKeRFRAJMIS8iEmAKeRGRACvIdgPilZSUuPLy8mw3Q0TkiLJ+/fodzrkRiR7LqZAvLy9n3bp12W6GiMgRxcySXrGtco2ISIAp5EVEAkwhLyISYDlVkxeR7Dt06BBNTU3s378/202RTgYNGsTo0aMZMGBAr5+jkBeRDpqamhg2bBjl5eVoVcLc4ZyjubmZpqYmxowZ0+vnqVyTJeEwlJdDXp73MxzOdotEPPv376e4uFgBn2PMjOLi4j5/w1JPPgvCYbjmGjh40Lvf0ODdBwiFstcukRgFfG7qz38X9eQzJByGYcPADK644nDAxxw8CFdeqR69iKSXQj4DwmH4+Jl5fPRgAZFVxqGfFHDfVfO67BeJQFWVgl6Obs3NzVRWVlJZWcnIkSMZNWpU+/2DnXtHSVx99dW89dZb3e7zwAMPEE7T/2zTpk1j7NixTJgwgc985jPcdNNN7Ny5s9vnRCIR7rrrrrQcvzs5NZ/85MmTXdCueF1YFeaWqdcyeMAB4r9pOQe/e/ULXHD3s12eU1YG9fWZa6NIvE2bNnHqqadmuxkAfO9732Po0KH867/+a4ftzjmcc+Tl5UY/ddq0adx///3tH0Tf/va3efXVV3nuueeSPqe1tZWSkhI+/vjjPh0r0X8fM1vvnJucaP/ceIcCaNm/hWlZXsh3z7uCooEdAx68ss2M055j1tSuPYnGxgw1UiQNMjWI4O2332b8+PFcd911TJo0ia1bt1JVVcXkyZOpqKjgjjvuaN932rRpbNiwgdbWVoYPH878+fOZOHEiZ599Nh988AEAt912G4sWLWrff/78+UyZMoWxY8eydu1aAPbu3cs///M/M3HiRGbNmsXkyZPZsGFDt+0cOHAgP/zhD9m8eTOvv/46ABdffDFnnHEGFRUVLF26FID58+eze/duKisrufLKK5PulyqFvA+2PTyKq8deQVHhwS7hHs8MFs++mbpF5bStyqNuUTmzpoYp7byktEiOCoe9EmNDg/fttKHB35LjG2+8wbXXXsvLL7/MqFGjuOuuu1i3bh0bN27kmWee4Y033ujynJ07d3LeeeexceNGzj77bJYtW5bwtZ1zvPjii/zgBz9o/8C47777GDlyJBs3bmT+/Pm8/PLLvWpnQUEBEyZM4M033wRgxYoVrF+/npdeeol77rmHjz76iLvuuothw4axYcMGfvKTnyTdL1UK+TT6ww/mEVllfHLo+92Ge7ySYc2Uj2ggzxzlIxp4ZE4Vq2pUlJcjQ3U1tLR03NbS4m33w0knncRnP/vZ9vurV69m0qRJTJo0iU2bNiUM+cGDB3PhhRcCcMYZZ1CfpBb61a9+tcs+zz//PDNnzgRg4sSJVFRU9Lqt8aXwe++9t/2bRFNTE++8807C5/R2v77QEMo0eeWuCs478Y1eh3tM5/2HFLYwragab+1okdyWrLToV8lxyJAh7bc3b97M4sWLefHFFxk+fDhXXHFFwjHkAwcObL+dn59Pa2trwtcuLCzssk9/z1m2trby2muvceqpp/Lss8/yxz/+kRdeeIHBgwczbdq0hO3s7X59pZ58ip4Ph2lbZZzWj4BPqiXprKEiOSVZaTETJcddu3YxbNgwjjnmGLZu3crTTz+d9mNMmzaNNWvWAPDqq68m/KbQ2cGDB/nOd77DySefzLhx49i5cyfHHXccgwcP5vXXX+ell14CvJIO0P6Bkmy/VCnkU/D0/OmcwxXk53XtkafGoE4lG8l9NTVQVNRxW1GRt91vkyZNYty4cYwfP565c+dyzjnnpP0YN954I++99x4TJkzgRz/6EePHj+cTn/hEwn0vu+wyJkyYwGmnncbBgwf55S9/CcCXvvQlWlpamDhxInfccQdnnnlm+3OuvfZaJkyYwJVXXtntfqnQEMp+CIdhWvMoSot7X3vvs6IyuKTepxcXSa6vQyjDYa8G39jo9eBraoJz5XZrayutra0MGjSIzZs3M2PGDDZv3tzeC8+Gvg6hVE2+jxZWhfnWOVcxsLgtLQHvXJJvAS0aRylHhlAoOKHe2Z49e/jCF75Aa2srzjkefvjhrAZ8fxxZrc2yXUuL+O55+9LWe49EoHlPMSOOae76YJHGUYpk2/Dhw1m/fn22m5ES1eR76cCKfIYNTl/AgxfwN69czN4DnYqa+UUwMQNFTREJPIV8D6ZPh4YloxhYEEl7/b14aDOr14aYu7SW+u1lRCJG00dlMKUWxgT0+6+IZJTKNd3Yct8onrn6fSDdo2c8EZcPwOq1IVavDbUfJ3J9+o8lIkcn9eQTqKiAluUDGX2cN3rGrxE0eXltXbZpSgMRSSeFfJxw2Av0n86uYPDAQ/4Nj4xq3FHW4b5ZZsYXi+SydEw1DLBs2TL+/ve/t9/vzfTDvdHa2kp+fj6VlZVUVFRQWVnJokWLiEQi3T7v3Xff5Wc/+1nKx+8r38s1ZnYBsBjIB5Y65/yfQLkfwmFvMY//+s50JqTz6tUknINb19R02RbUoWgivVVcXNw+02OyqYZ7Y9myZUyaNImRI0cCsHz58rS1MTaxGMC2bduYOXMmu3fvZsGCBUmfEwv52Fw4meJrT97M8oEHgAuBccAsMxvn5zH74/lwmIv3DSWyyphx2nO+BzzA/kOD2uvwMWVlSXYWyWV1YXiiHH6a5/308WrtFStWMGXKFCorK5k3bx6RSITW1lZmz57Naaedxvjx41myZAk///nP2bBhA5dddln7N4DeTD+8efNmzjzzTKZMmcKCBQsYPnx4j206/vjjefjhh7nvvvsAeOedd/jc5z7H6aefzhlnnMFf/vIXwJta+Pe//z2VlZUsWbIk6X7p5ndPfgrwtnPuXQAz+xnwZaDnCSAyIByGPb+fR9XnH8LiRjGe/+8ZOLjbz8nHj+LtbacA3lzcgwfD+edn4Ngi3bj99tt7vRjHsOb/y8iGBeS56ERaLQ1EXpjD37duZXfxxSm3ZceOHbS0tPDWW2/xt7/9jZUrV7J8+XIKCgpYsGAB99xzD6WlpTQ0NPCLX/wC8Oa0OeaYYxg7diwLFizg1FNPpa6ujn379lFfX8+AAQPYuXMnJ510EmvWrOE//uM/uPvuu6mqqmLOnDlcfvnlXHDBBaxatYpIJNKlxNPa2ppw+969e3nhhRcYNGgQDzzwAIWFhbz77rtUVVWxZs0arr/+esLhMA888AAAu3fv7rDfTTfd5EvQ+x3yo4AtcfebgA4TMphZFVAFUJrBs47hMHz0zDyu/8eHMtJz78Jg1LHvM+rY9znQWsj+gjF84vjjs9AQkf4b8f69hwM+Ks/tZ8T796Yl5OP9+c9/5tVXX+VrX/saAPv37+eEE05g2rRp1NXVUVNTw7nnnsu0adN6fK1BgwZx7rnnAjB+/Hhi06m88sor1NbWAnDRRRexePHiPrfz4MGD3Hnnnbz11lvk5+fTmGRKzs77NTU19flYveF3yCeKzw6T5TjnaoFa8Oau8bk97T7uJuD/cFumWhFzAPIbYcptGh8vWbdp0ybGjh3bu53Xb024ecDBrb1/jW6UlJQwdOhQxo4dy4gRI6iqquLOO+/sst+mTZv47W9/y6OPPsqLL75IbW0tgwcPpry8vL0d8fcLCwvbt7/88su8+eabjB07lry8vPafH374Yfv9eK2trV22/+1vf2PIkCGcddZZ3HbbbVRUVPDkk09y6NCh9vZv2bKl/TaQcD8/+D26pgk4Me7+aOB9n4/ZrYoKuPycMN/8xx9npwefTFsLbPRppQURvySbfsOHaTmmT5/OmjVr2LFjB+CNwmlsbGT79u045/j617/O97//ff76178C3snR3bt39+kYU6ZM4fHHHwfo9UiYDz74gG9+85vceOONgDdl8AknnICZsWLFivY56Tu3J9l+6eZ3yL8EnGJmY8xsIDATeNLnYyYUDnt17zfegIWXVpNnuTP7ZjtNSiZHmok13jQc8XyaluO0007j9ttvZ/r06UyYMIEZM2awbds2tmzZwrnnnktlZSVz585l4cKFgDdkcs6cOX0aerlkyRLuvvtupkyZwgcffJB0WuHY2qzjxo1jxowZXHTRRVRHl8O64YYbWLp0KWeddRYNDQ3ti5GcfvrptLW1MXHiRJYsWZJ0v3TzfaphM/sisAhvCOUy51zS//p+TTU8bx489NDh+22r8rIa8klnntT0wpID+jrVMHVh71toS6PXg59Yc8SWHffu3UtRURFmxqpVq3j88cd57LHHst2sDnJuqmHn3FPAU34fJ5Hnw2HKPqrm/nMa+fbYUm5dU8PqtSEad5RSPiJ7qy/t3j+U/LwIQwoPL46590ARQ87WlVByBBoTOmJDvbOXXnqJW265hUgkwrHHHpvWsfXZEthFQ54Ph/ls6zUUDjj8NS32q0ZcHnmW/gnHemPvgSLmLvXO3i+8tJrS4kYam0u55//VsORXwfgfRY5sfe7JS0blXE8+Wz6z52YKh3Wsw8VCPd8i9PezLeKsX6Ue56BhR1n7twmg/eeAARCADoMEiHMOy6mRCQL9W1g8sHPXFA9NsBBHHDP6HPStbfk8+Mx1Xed/76XSkkYWXlrNfVfNo25ROW2r8qhbVM7Ms7Weq+SOQYMG0dzc7NtoD+kf5xzNzc0MGjSoT88LbLnGha3HcoxzsGN3MSXDDn8gdPecSMTInx1h1tRwe6mlec9xFBbsZ9jgvb0u/3Q+8br3QBHfWFbLhdeFNHeNZN2hQ4doampi//79Pe8sGTVo0CBGjx7NgAEDOmzvrlwT2JDf/uOSxMvqxWlty2fAla3t92dNDROed0XSsK7fXsaYW+o77L/w0mpKSxrZs6+oT0Gf6LUrbq2ntlaTlIlI33QX8oEr14TDUF4ON69czP5DA5Lu5xz8+LmqDttWrw3RsCPxLGERZx1mjZw1Ncwjc6ooH9FAnjmOKep/wAOUFjfS0uKtei8iki6BCvlwGKqqoKHBC+xrape3L6u3q2UIbZE8nPN68A88801uXPFgl9e4dU1Nl5p7xBkPPnNdh1kjF15a3WEIZKqa9xwHQJJpLkRE+iVQo2uqq6ElLnfjl9Xrrdj+8cMb40fExJSW+JPGWhlKRNIpECEfDnsB39CL65uKi6G5+1J9rz4c0n1BVfHQDykq0spQIpJeR3y5Jr5Ek0xZmVeDdw527EjP4hyJyjr7Dw1gV8uQfo3Bb2wu5aqrdNJVRNLriA/5ziWazhL1jmtqvO19YQarVnn/iou93v7cpbXtNf/67WVcU7ucD/eW9PkE7N4DRdy6poansjL5g4gE2RFfrunuRGVZmRfoiXrHgwcf/nDo7YVRoZD3zWHfPu9+orLOqnmze9nyrlfB6gJDEUm3Iz7kS0sTl2rKyqC+vuv2WHknvvffm4CPnRDt6ZtDX2r1zlmHcfc66Soi6XbEl2sSlV66O4HZU0gnEv96PQ1xTDYEM5GIy2PW1MNTGuikq4ik2xEf8qEQ1NZ6PXcz72d3V432dhx6rHQSez3wLrLqqdefqFafbL6bgvw2HplTxaypYYqLddJVRNLviA958MKxvh4iEe9nd2GZrCRSXNzxg2LlSi/QYyWfnkbwxMRPdRAbY3/jigeZu7SW1rb8LvsPKWzhrsuq6cd6wSIiPQrs3DXJJKrJFxUl7/2Hw3DVVdDWlvw18/K8D5jYVAedFwOZu7SW1WtDSVekcs6wUCSVX0tEjmJH1dw1PelLeSf2gdBdwIMX8EVFiac6GFLYwsJLvQlpGnck/hrRsKOUggJvmUIRkXQ66kIeel/e6e1J2tC0MK8vLKesJHE9p7TYOxGQ6KRsbIx8W5u3Dq2CXkTS6agM+d7qzUnaWVPDPHyNNxtlsnHujc1eDz7RSdlYKScmdpJXRCQdjvhx8n5KNgY/Jj+/59koDxwayJDCPbStyqNxh3ciNn5sfGc9lYZERPpCPfluJBuDv2qVN/ImEkk+G6VzsH1XMQ7HiGOayTNH+YgGHplTxY3/M0xeknc+2XYRkf5QpHSjp5O0paXdnUwtY++BoQwacKjD9iGFLSy5uppvfCPxMc28E74iIumgkO9Bdydpa2rg+08kP5matJe/t4EHZ5TzL5/vmuZtbVodSkTSRyGfglAIBp8a4hvLDp9M3b6rmJYDg1k1bzaRSOK31wxoaeD+2VUdpjWI0epQIpIuCvkUhMOwYgWEnw8x5pZ6rnhoJUWF+9pr8AX5bd1OgxAbQz9rapi6ReW0rcqjblE5N1yseo2IpMdRd8VrOpWXdxx9U7eoPOEMlK1t+eTntSUcYhlxsO9gUYcROq2uiIKptTBGk9mISM90xatPOpdVktXg8yxCw47Ey1FFIvldhmAWWAtsVGFeRFKnkE9B58nOko20iU1UlugEbV5ekoHxLSrMi0jqFPIp6DyOvrtpC5Jd7dqYpIdPkVYQEZHU6YrXFMSGU1ZXe6WbkhIYMNArvDvnLQqy/L+vYs1fvB0TLRcIdJm5kvwimKgVREQkderJp6h9HP07YZbMvJqBthfwhknm50W44YL/pHVzmFWrEi8e3rmHT1EZTNFJVxFJD42uSZcnyqElyUQ3RWVwSX2Pc9MnW5dWRKQ7Gl2TCd2dKI0+Fgp54+oHDjz8UPwY+ddqyqFOY+RFJH0U8unS3YnSuMdCIbj2Wu92bCWp8hEN5JljqDXAi1UKehFJG514TVVd2BvTnqxUA9C653Bwb6zm/nMa+fbYUoYU7uk6TXFbdIy8avIikgYK+VTUhb2ed1sPy0cdbObAH68BcxQWHCLPoHxEQ/IpDzRGXkTSRCGfio3ViQPe8sF1PLtaOOBg192SrCSlMfIiki6+1eTN7Htm9p6ZbYj++6Jfx8qaZD1u1/vlnTr35vce0Bh5EUkfv0+83uucq4z+e8rnY2Vesh635ff6JXbsLu5wFex3n9AYeRFJH42uScXEGu/q1Hj5RXBSFS0HO24/cGgg+w8N6LBt74Eibl65mDG31JM/O0LFrfWceakCXkTSx++Qv8HMXjGzZWZ2bKIdzKzKzNaZ2brt27f73Jw0GxPyrk4tKgPirlad8iBzH+k4T83Vtcu4pnZ5+7amj8p4eWAta98LJVxaUEQkHVK64tXMngVGJnioGngB2AE44E7gBOfcNd293hF9xWsnneea76y4GBYvVqiLSOq6u+I1pdE1zrnpvWzAI8CvUznWkaamBmbP7npiNaa5GaqqvNsKehHxi5+ja06Iu/sV4DW/jpWLQiG47rpuhkkCLS1atFtE/OXnOPn/Y2aVeOWaeuAbPh4r54TD8NRTXk8+Pz/5pGRatFtE/ORbyDvnZvv12rkuHPZKMS3R66Ta2rwefaLSTefVpURE0klDKH1QXX044GOc61q6KSryavciIn5RyPsgWQnGOW9UjYZMikimaO4aH5SWJh8+uW8frFypcBeRzFBP3gc1NTBgQOLHNKJGRDJJIe+T7oZOakSNiGSKQt4H1dVwMG5m4fgl/uoWlXPDxVr5SUQyQzV5H8T31GNL/MVWgCof0cA9l1ZBHZptUkR8p568D+LHvi+8tLrLEn8FFl3iT0TEZwr5dKoLwxPl1NXk0bC4nFlTw5SWJCnAa4k/EckAhXy6xNZ7bWnAzFFa0sDSuVU07z4u8f5a4k9EMkAhny4J1nstGtjCiGISLyyiJf5EJAMU8umSpPwSOfAhN/20lj2u08IiOukqIhmgkE+XJOWXxuZS7nsyxPFV9YRdBC6pV8CLSMYo5NMlwXqvew8UcesaryyjK11FJBsU8ukSt95rbF3XuUtrWb32cK9dV7qKSKbpYqh0GhOCMSE+VZ54gjLnvLVfa2o0QZmIZIZ68j6oqfHmik+kocFbUCSsmQ1EJAMU8j4Ihby54svKEj+u+ryIZIpC3iehENTXJ5+NUvV5EckEhbzPkq3hqrVdRSQTFPI+S1Sf19quIpIpCnmfxdfntbariGSahlBmQCikUBeR7FBPXkQkwBTyKQiHvYub8vK8nxr7LiK5RiHfT+Gwd1FTQ4N3JWtfLnLSh4OIZIpCvp+qq72LmuL15iKnVD4cRET6SiHfT8kuZur2Iqe6MOd9XM7u2jzqFnnLA4KugBUR/yjk+ynZxUzHJVntL7Y84OhjG8gzR/mIBh6ZU9Ue9LoCVkT8oJDvp5oaGDiw6/Zdu5KUXhIsDziksIWFl3pdeF0BKyJ+UMj3UygEw4Z13X7oUOLSi9ubuKteWtyoK2BFxDcK+RR8+GHi7bHSS2wUjRk07EjcVX9/Z6mugBUR3yjkU9Dd5GPxo2gAbl1Tw94DHSexaTlYxOgv1ijgRcQ3CvkUdDf5WOchlqvXhpi7tJb67XHLAz5Sq0W9RcRX5pzLdhvaTZ482a1bty7bzeiTcNgL9MZGrwcfW9ovL88bB9+dsjJvznkRkVSY2Xrn3OREj2mCshQlm3ystDTxOq8xOtkqIpmgco1PEpVyYqtEabphEckUhbxPEs0jv3KlV8Kpr1fAi0hmpBTyZvZ1M3vdzCJmNrnTY981s7fN7C0z+6fUmnlkiq3zGoko2EUkO1Ktyb8GfBV4OH6jmY0DZgIVwD8Az5rZp51zbSkeT0RE+iClnrxzbpNz7q0ED30Z+Jlz7oBzrg54G5iSyrFERKTv/KrJjwK2xN1vim7rwsyqzGydma3bvn27T80RETk69RjyZvasmb2W4N+Xu3tagm0JR40752qdc5Odc5NHjBjR23YHihYRERG/9FiTd85N78frNgEnxt0fDbzfj9cJvNj0B7GrY2OLiIBO1IpI6vwq1zwJzDSzQjMbA5wCvOjTsY5o/V1hSkSkN1IdQvkVM2sCzgZ+Y2ZPAzjnXgfWAG8A/wVcr5E1ifVrhSkRkV5KaQilc+5x4PEkj9UAunC/B8mmP9AiIiKSDrriNcu6m8lSRCRVCvksSzT9gea1EZF0Ucj7bN48KCjwArygwLvfmaY/EBG/aKphH82bBw89dPh+W9vh+w8+mJ02icjRRT15H9XW9m27iEi6KeR91JZk0Giy7SIi6aaQ91F+ft+2i4ikm0LeR7HpCXq7XUQk3XTi1UcPPgiTS8J8oaSaE4sb2dJcynM7arjmDg2fEZHMUMj7qS7MNRVV0OZNTlNW0sA1x1dBHTBGQS8i/lO5xk8bq9sDvl1bi7ddRCQDFPJ+akkyy1iy7SIiaaaQ91NRklnGkm0XEUkzhbyfJtZAfqfZx/KLvO0iIhmgkPfTmBBMqYWiMsC8n1NqddJVRDJGIZ9mXdZrXRuCS+rh8oj3UwEvIhmkIZRppPVaRSTXqCefRlqvVURyjUI+jbReq4jkGoV8GiVbl1XrtYpItijk00jrtYpIrlHIp5HWaxWRXKPRNWkWCinURSR3qCcvIhJgCnkRkQBTyIuIBJhCXkQkwBTyIiIBppAXEQkwhbyISIAp5EVEAkwhLyISYAp5EZEAU8iLiASYQl5EJMAU8iIiAaaQFxEJMIW8iEiAKeRFRAIspZA3s6+b2etmFjGzyXHby81sn5ltiP77cepNFRGRvkp1ZajXgK8CDyd47B3nXGWKry8iIilIKeSdc5sAzCw9rRERkTKwVicAAATtSURBVLTysyY/xsxeNrP/NrPPJdvJzKrMbJ2Zrdu+fbuPzREROfr02JM3s2eBkQkeqnbO/SrJ07YCpc65ZjM7A3jCzCqcc7s67+icqwVqASZPnux633QREelJjyHvnJve1xd1zh0ADkRvrzezd4BPA+v63EIREek3X8o1ZjbCzPKjtz8FnAK868exREQkuVSHUH7FzJqAs4HfmNnT0YfOBV4xs43AL4DrnHMfptZUERHpq1RH1zwOPJ5g+2PAY6m8toiIpE5XvIqIBJhCXkQkwBTyIiIBppAXEQkwhbyISIAp5EVEAkwhLyISYAp5EZEAU8iLiASYQl5EJMAU8iIiAaaQFxEJMIW8iEiAKeRFRAJMIS8iEmAKeRGRAFPIi4gEmEJeRCTAFPIiIgGmkBcRCTCFvIhIgCnkRUQCTCEvIhJgCnkRkQBTyIuIBJhCXkQkwBTyIiIBppAXEQkwhXyWhcNQXg55ed7PcDjbLRKRICnIdgOOZuEwVFVBS4t3v6HBuw8QCmWvXSISHOrJZ1F19eGAj2lp8baLiKSDQj6LGhv7tl1EpK8U8llUWtq37SIifaWQz6KaGigq6ritqMjbLiKSDgr5LAqFoLYWysrAzPtZW6uTriKSPhpdk2WhkEJdRPyjnryISIAp5EVEAkwhLyISYAp5EZEAU8iLiASYOeey3YZ2ZrYdaMh2O4ASYEe2G5FD9H50pPejI70fHWXj/Shzzo1I9EBOhXyuMLN1zrnJ2W5HrtD70ZHej470fnSUa++HyjUiIgGmkBcRCTCFfGK12W5AjtH70ZHej470fnSUU++HavIiIgGmnryISIAp5EVEAkwhH8fMLjCzt8zsbTObn+32ZJuZ1ZvZq2a2wczWZbs92WBmy8zsAzN7LW7bcWb2jJltjv48NpttzJQk78X3zOy96N/IBjP7YjbbmElmdqKZ/d7MNpnZ62Z2c3R7Tv19KOSjzCwfeAC4EBgHzDKzcdltVU74vHOuMpfG/WbYo8AFnbbNB55zzp0CPBe9fzR4lK7vBcC90b+RSufcUxluUza1At9yzp0KnAVcH82MnPr7UMgfNgV42zn3rnPuIPAz4MtZbpNkmXPuj8CHnTZ/GVgRvb0CuCSjjcqSJO/FUcs5t9U599fo7d3AJmAUOfb3oZA/bBSwJe5+U3Tb0cwBvzOz9WZWle3G5JDjnXNbwfsfHfhkltuTbTeY2SvRcs5RUbrqzMzKgdOBv5Bjfx8K+cMswbajfXzpOc65SXglrOvN7NxsN0hyzkPASUAlsBX4UXabk3lmNhR4DLjFObcr2+3pTCF/WBNwYtz90cD7WWpLTnDOvR/9+QHwOF5JS2CbmZ0AEP35QZbbkzXOuW3OuTbnXAR4hKPsb8TMBuAFfNg598vo5pz6+1DIH/YScIqZjTGzgcBM4MkstylrzGyImQ2L3QZmAK91/6yjxpPAVdHbVwG/ymJbsioWZlFf4Sj6GzEzA/4T2OScuyfuoZz6+9AVr3Giw78WAfnAMudcTZablDVm9im83jt4C77/9Gh8P8xsNXA+3vSx24DbgSeANUAp0Ah83TkX+BOSSd6L8/FKNQ6oB74Rq0cHnZlNA/4EvApEoptvxavL58zfh0JeRCTAVK4REQkwhbyISIAp5EVEAkwhLyISYAp5EZEAU8iLiASYQl5EJMD+P3yEXyXqQ8ueAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Residuals for the Training and Testing data\n",
    "\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression on multiple input features(Scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"Critic_Score\", \"User_Score\", \"PlayScore\", \"GameScore\", \"CriticScore\"]]\n",
    "y = data['TopSellers'].values.reshape(-1, 1)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1195, 23)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop(['TopSellers'], axis=1)\n",
    "y = data['TopSellers'].values.reshape(-1, 1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6169195084737055\n",
      "Testing Score: 0.6324661301731256\n"
     ]
    }
   ],
   "source": [
    "LR = model.fit(X_train, y_train)\n",
    "LR\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07027464984531034, R2: 0.6324661301731256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "r2 = model.score(X_test, y_test)\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic_Score    0.338786\n",
       "PlayScore       0.355016\n",
       "CriticScore     0.361259\n",
       "Critc_Count     0.438886\n",
       "Critic_Count    0.440206\n",
       "EU_Sales        0.570726\n",
       "Other_Sales     0.590206\n",
       "NA_Sales        0.616170\n",
       "Global_Sales    0.633337\n",
       "TopSellers      1.000000\n",
       "Name: TopSellers, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = data.corr()[\"TopSellers\"].sort_values()\n",
    "correlations.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1195, 5)\n",
      "(1195, 1)\n"
     ]
    }
   ],
   "source": [
    "features = data[[\"Critic_Score\", \"User_Score\", \"PlayScore\", \"GameScore\", \"CriticScore\", \"TopSellers\"]]\n",
    "\n",
    "X = features.drop(['TopSellers'], axis=1)\n",
    "y = features['TopSellers'].values.reshape(-1, 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 802\n",
      "Trainable params: 802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 - 0s - loss: 0.5873 - accuracy: 0.7522\n",
      "Epoch 2/100\n",
      "28/28 - 0s - loss: 0.5713 - accuracy: 0.7522\n",
      "Epoch 3/100\n",
      "28/28 - 0s - loss: 0.5564 - accuracy: 0.7522\n",
      "Epoch 4/100\n",
      "28/28 - 0s - loss: 0.5481 - accuracy: 0.7522\n",
      "Epoch 5/100\n",
      "28/28 - 0s - loss: 0.5337 - accuracy: 0.7522\n",
      "Epoch 6/100\n",
      "28/28 - 0s - loss: 0.5261 - accuracy: 0.7522\n",
      "Epoch 7/100\n",
      "28/28 - 0s - loss: 0.5176 - accuracy: 0.7522\n",
      "Epoch 8/100\n",
      "28/28 - 0s - loss: 0.5068 - accuracy: 0.7567\n",
      "Epoch 9/100\n",
      "28/28 - 0s - loss: 0.5068 - accuracy: 0.7600\n",
      "Epoch 10/100\n",
      "28/28 - 0s - loss: 0.4975 - accuracy: 0.7567\n",
      "Epoch 11/100\n",
      "28/28 - 0s - loss: 0.4909 - accuracy: 0.7634\n",
      "Epoch 12/100\n",
      "28/28 - 0s - loss: 0.4853 - accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "28/28 - 0s - loss: 0.4868 - accuracy: 0.7723\n",
      "Epoch 14/100\n",
      "28/28 - 0s - loss: 0.4822 - accuracy: 0.7712\n",
      "Epoch 15/100\n",
      "28/28 - 0s - loss: 0.4796 - accuracy: 0.7723\n",
      "Epoch 16/100\n",
      "28/28 - 0s - loss: 0.4812 - accuracy: 0.7723\n",
      "Epoch 17/100\n",
      "28/28 - 0s - loss: 0.4768 - accuracy: 0.7824\n",
      "Epoch 18/100\n",
      "28/28 - 0s - loss: 0.4746 - accuracy: 0.7746\n",
      "Epoch 19/100\n",
      "28/28 - 0s - loss: 0.4745 - accuracy: 0.7835\n",
      "Epoch 20/100\n",
      "28/28 - 0s - loss: 0.4786 - accuracy: 0.7824\n",
      "Epoch 21/100\n",
      "28/28 - 0s - loss: 0.4744 - accuracy: 0.7824\n",
      "Epoch 22/100\n",
      "28/28 - 0s - loss: 0.4742 - accuracy: 0.7879\n",
      "Epoch 23/100\n",
      "28/28 - 0s - loss: 0.4728 - accuracy: 0.7801\n",
      "Epoch 24/100\n",
      "28/28 - 0s - loss: 0.4709 - accuracy: 0.7824\n",
      "Epoch 25/100\n",
      "28/28 - 0s - loss: 0.4705 - accuracy: 0.7835\n",
      "Epoch 26/100\n",
      "28/28 - 0s - loss: 0.4710 - accuracy: 0.7902\n",
      "Epoch 27/100\n",
      "28/28 - 0s - loss: 0.4702 - accuracy: 0.7846\n",
      "Epoch 28/100\n",
      "28/28 - 0s - loss: 0.4736 - accuracy: 0.7812\n",
      "Epoch 29/100\n",
      "28/28 - 0s - loss: 0.4700 - accuracy: 0.7879\n",
      "Epoch 30/100\n",
      "28/28 - 0s - loss: 0.4707 - accuracy: 0.7879\n",
      "Epoch 31/100\n",
      "28/28 - 0s - loss: 0.4688 - accuracy: 0.7846\n",
      "Epoch 32/100\n",
      "28/28 - 0s - loss: 0.4685 - accuracy: 0.7879\n",
      "Epoch 33/100\n",
      "28/28 - 0s - loss: 0.4776 - accuracy: 0.7768\n",
      "Epoch 34/100\n",
      "28/28 - 0s - loss: 0.4827 - accuracy: 0.7790\n",
      "Epoch 35/100\n",
      "28/28 - 0s - loss: 0.4762 - accuracy: 0.7801\n",
      "Epoch 36/100\n",
      "28/28 - 0s - loss: 0.4711 - accuracy: 0.7812\n",
      "Epoch 37/100\n",
      "28/28 - 0s - loss: 0.4697 - accuracy: 0.7891\n",
      "Epoch 38/100\n",
      "28/28 - 0s - loss: 0.4697 - accuracy: 0.7846\n",
      "Epoch 39/100\n",
      "28/28 - 0s - loss: 0.4681 - accuracy: 0.7846\n",
      "Epoch 40/100\n",
      "28/28 - 0s - loss: 0.4665 - accuracy: 0.7913\n",
      "Epoch 41/100\n",
      "28/28 - 0s - loss: 0.4707 - accuracy: 0.7824\n",
      "Epoch 42/100\n",
      "28/28 - 0s - loss: 0.4701 - accuracy: 0.7790\n",
      "Epoch 43/100\n",
      "28/28 - 0s - loss: 0.4693 - accuracy: 0.7790\n",
      "Epoch 44/100\n",
      "28/28 - 0s - loss: 0.4658 - accuracy: 0.7902\n",
      "Epoch 45/100\n",
      "28/28 - 0s - loss: 0.4753 - accuracy: 0.7679\n",
      "Epoch 46/100\n",
      "28/28 - 0s - loss: 0.4730 - accuracy: 0.7879\n",
      "Epoch 47/100\n",
      "28/28 - 0s - loss: 0.4695 - accuracy: 0.7835\n",
      "Epoch 48/100\n",
      "28/28 - 0s - loss: 0.4668 - accuracy: 0.7902\n",
      "Epoch 49/100\n",
      "28/28 - 0s - loss: 0.4649 - accuracy: 0.7868\n",
      "Epoch 50/100\n",
      "28/28 - 0s - loss: 0.4721 - accuracy: 0.7846\n",
      "Epoch 51/100\n",
      "28/28 - 0s - loss: 0.4713 - accuracy: 0.7824\n",
      "Epoch 52/100\n",
      "28/28 - 0s - loss: 0.4673 - accuracy: 0.7857\n",
      "Epoch 53/100\n",
      "28/28 - 0s - loss: 0.4692 - accuracy: 0.7879\n",
      "Epoch 54/100\n",
      "28/28 - 0s - loss: 0.4669 - accuracy: 0.7846\n",
      "Epoch 55/100\n",
      "28/28 - 0s - loss: 0.4661 - accuracy: 0.7935\n",
      "Epoch 56/100\n",
      "28/28 - 0s - loss: 0.4675 - accuracy: 0.7946\n",
      "Epoch 57/100\n",
      "28/28 - 0s - loss: 0.4670 - accuracy: 0.7891\n",
      "Epoch 58/100\n",
      "28/28 - 0s - loss: 0.4652 - accuracy: 0.7879\n",
      "Epoch 59/100\n",
      "28/28 - 0s - loss: 0.4659 - accuracy: 0.7868\n",
      "Epoch 60/100\n",
      "28/28 - 0s - loss: 0.4695 - accuracy: 0.7924\n",
      "Epoch 61/100\n",
      "28/28 - 0s - loss: 0.4654 - accuracy: 0.7913\n",
      "Epoch 62/100\n",
      "28/28 - 0s - loss: 0.4652 - accuracy: 0.7868\n",
      "Epoch 63/100\n",
      "28/28 - 0s - loss: 0.4655 - accuracy: 0.7913\n",
      "Epoch 64/100\n",
      "28/28 - 0s - loss: 0.4652 - accuracy: 0.7812\n",
      "Epoch 65/100\n",
      "28/28 - 0s - loss: 0.4646 - accuracy: 0.7935\n",
      "Epoch 66/100\n",
      "28/28 - 0s - loss: 0.4659 - accuracy: 0.7846\n",
      "Epoch 67/100\n",
      "28/28 - 0s - loss: 0.4640 - accuracy: 0.7924\n",
      "Epoch 68/100\n",
      "28/28 - 0s - loss: 0.4660 - accuracy: 0.7891\n",
      "Epoch 69/100\n",
      "28/28 - 0s - loss: 0.4648 - accuracy: 0.7913\n",
      "Epoch 70/100\n",
      "28/28 - 0s - loss: 0.4666 - accuracy: 0.7946\n",
      "Epoch 71/100\n",
      "28/28 - 0s - loss: 0.4684 - accuracy: 0.7891\n",
      "Epoch 72/100\n",
      "28/28 - 0s - loss: 0.4679 - accuracy: 0.7935\n",
      "Epoch 73/100\n",
      "28/28 - 0s - loss: 0.4658 - accuracy: 0.7879\n",
      "Epoch 74/100\n",
      "28/28 - 0s - loss: 0.4687 - accuracy: 0.7913\n",
      "Epoch 75/100\n",
      "28/28 - 0s - loss: 0.4652 - accuracy: 0.7935\n",
      "Epoch 76/100\n",
      "28/28 - 0s - loss: 0.4637 - accuracy: 0.7891\n",
      "Epoch 77/100\n",
      "28/28 - 0s - loss: 0.4658 - accuracy: 0.7868\n",
      "Epoch 78/100\n",
      "28/28 - 0s - loss: 0.4642 - accuracy: 0.7913\n",
      "Epoch 79/100\n",
      "28/28 - 0s - loss: 0.4635 - accuracy: 0.7857\n",
      "Epoch 80/100\n",
      "28/28 - 0s - loss: 0.4654 - accuracy: 0.7857\n",
      "Epoch 81/100\n",
      "28/28 - 0s - loss: 0.4642 - accuracy: 0.7913\n",
      "Epoch 82/100\n",
      "28/28 - 0s - loss: 0.4646 - accuracy: 0.7902\n",
      "Epoch 83/100\n",
      "28/28 - 0s - loss: 0.4654 - accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "28/28 - 0s - loss: 0.4627 - accuracy: 0.7868\n",
      "Epoch 85/100\n",
      "28/28 - 0s - loss: 0.4659 - accuracy: 0.7946\n",
      "Epoch 86/100\n",
      "28/28 - 0s - loss: 0.4639 - accuracy: 0.7891\n",
      "Epoch 87/100\n",
      "28/28 - 0s - loss: 0.4640 - accuracy: 0.7879\n",
      "Epoch 88/100\n",
      "28/28 - 0s - loss: 0.4618 - accuracy: 0.7924\n",
      "Epoch 89/100\n",
      "28/28 - 0s - loss: 0.4722 - accuracy: 0.7746\n",
      "Epoch 90/100\n",
      "28/28 - 0s - loss: 0.4642 - accuracy: 0.7913\n",
      "Epoch 91/100\n",
      "28/28 - 0s - loss: 0.4621 - accuracy: 0.7946\n",
      "Epoch 92/100\n",
      "28/28 - 0s - loss: 0.4619 - accuracy: 0.7913\n",
      "Epoch 93/100\n",
      "28/28 - 0s - loss: 0.4653 - accuracy: 0.7857\n",
      "Epoch 94/100\n",
      "28/28 - 0s - loss: 0.4623 - accuracy: 0.7935\n",
      "Epoch 95/100\n",
      "28/28 - 0s - loss: 0.4620 - accuracy: 0.7913\n",
      "Epoch 96/100\n",
      "28/28 - 0s - loss: 0.4623 - accuracy: 0.7868\n",
      "Epoch 97/100\n",
      "28/28 - 0s - loss: 0.4630 - accuracy: 0.7924\n",
      "Epoch 98/100\n",
      "28/28 - 0s - loss: 0.4646 - accuracy: 0.7812\n",
      "Epoch 99/100\n",
      "28/28 - 0s - loss: 0.4638 - accuracy: 0.7846\n",
      "Epoch 100/100\n",
      "28/28 - 0s - loss: 0.4617 - accuracy: 0.7891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3a73a5cc8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "deep_model.add(Dense(units=100, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 10,902\n",
      "Trainable params: 10,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "28/28 - 0s - loss: 0.6164 - accuracy: 0.7020\n",
      "Epoch 2/100\n",
      "28/28 - 0s - loss: 0.5703 - accuracy: 0.7522\n",
      "Epoch 3/100\n",
      "28/28 - 0s - loss: 0.5407 - accuracy: 0.7522\n",
      "Epoch 4/100\n",
      "28/28 - 0s - loss: 0.5165 - accuracy: 0.7522\n",
      "Epoch 5/100\n",
      "28/28 - 0s - loss: 0.4965 - accuracy: 0.7634\n",
      "Epoch 6/100\n",
      "28/28 - 0s - loss: 0.4819 - accuracy: 0.7879\n",
      "Epoch 7/100\n",
      "28/28 - 0s - loss: 0.4772 - accuracy: 0.7857\n",
      "Epoch 8/100\n",
      "28/28 - 0s - loss: 0.4969 - accuracy: 0.7623\n",
      "Epoch 9/100\n",
      "28/28 - 0s - loss: 0.4757 - accuracy: 0.7902\n",
      "Epoch 10/100\n",
      "28/28 - 0s - loss: 0.4710 - accuracy: 0.7902\n",
      "Epoch 11/100\n",
      "28/28 - 0s - loss: 0.4716 - accuracy: 0.7879\n",
      "Epoch 12/100\n",
      "28/28 - 0s - loss: 0.4787 - accuracy: 0.7801\n",
      "Epoch 13/100\n",
      "28/28 - 0s - loss: 0.4750 - accuracy: 0.7779\n",
      "Epoch 14/100\n",
      "28/28 - 0s - loss: 0.4668 - accuracy: 0.7779\n",
      "Epoch 15/100\n",
      "28/28 - 0s - loss: 0.4678 - accuracy: 0.7846\n",
      "Epoch 16/100\n",
      "28/28 - 0s - loss: 0.4653 - accuracy: 0.7924\n",
      "Epoch 17/100\n",
      "28/28 - 0s - loss: 0.4683 - accuracy: 0.7824\n",
      "Epoch 18/100\n",
      "28/28 - 0s - loss: 0.4660 - accuracy: 0.7902\n",
      "Epoch 19/100\n",
      "28/28 - 0s - loss: 0.4658 - accuracy: 0.7801\n",
      "Epoch 20/100\n",
      "28/28 - 0s - loss: 0.4637 - accuracy: 0.7980\n",
      "Epoch 21/100\n",
      "28/28 - 0s - loss: 0.4651 - accuracy: 0.7835\n",
      "Epoch 22/100\n",
      "28/28 - 0s - loss: 0.4696 - accuracy: 0.7824\n",
      "Epoch 23/100\n",
      "28/28 - 0s - loss: 0.4740 - accuracy: 0.7980\n",
      "Epoch 24/100\n",
      "28/28 - 0s - loss: 0.4621 - accuracy: 0.7935\n",
      "Epoch 25/100\n",
      "28/28 - 0s - loss: 0.4626 - accuracy: 0.7924\n",
      "Epoch 26/100\n",
      "28/28 - 0s - loss: 0.4632 - accuracy: 0.7846\n",
      "Epoch 27/100\n",
      "28/28 - 0s - loss: 0.4686 - accuracy: 0.7812\n",
      "Epoch 28/100\n",
      "28/28 - 0s - loss: 0.4640 - accuracy: 0.7946\n",
      "Epoch 29/100\n",
      "28/28 - 0s - loss: 0.4681 - accuracy: 0.7835\n",
      "Epoch 30/100\n",
      "28/28 - 0s - loss: 0.4720 - accuracy: 0.7757\n",
      "Epoch 31/100\n",
      "28/28 - 0s - loss: 0.4661 - accuracy: 0.7824\n",
      "Epoch 32/100\n",
      "28/28 - 0s - loss: 0.4654 - accuracy: 0.7801\n",
      "Epoch 33/100\n",
      "28/28 - 0s - loss: 0.4622 - accuracy: 0.7913\n",
      "Epoch 34/100\n",
      "28/28 - 0s - loss: 0.4619 - accuracy: 0.7946\n",
      "Epoch 35/100\n",
      "28/28 - 0s - loss: 0.4643 - accuracy: 0.7768\n",
      "Epoch 36/100\n",
      "28/28 - 0s - loss: 0.4735 - accuracy: 0.7801\n",
      "Epoch 37/100\n",
      "28/28 - 0s - loss: 0.4634 - accuracy: 0.7868\n",
      "Epoch 38/100\n",
      "28/28 - 0s - loss: 0.4575 - accuracy: 0.7846\n",
      "Epoch 39/100\n",
      "28/28 - 0s - loss: 0.4665 - accuracy: 0.7701\n",
      "Epoch 40/100\n",
      "28/28 - 0s - loss: 0.4597 - accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "28/28 - 0s - loss: 0.4595 - accuracy: 0.7879\n",
      "Epoch 42/100\n",
      "28/28 - 0s - loss: 0.4617 - accuracy: 0.7946\n",
      "Epoch 43/100\n",
      "28/28 - 0s - loss: 0.4705 - accuracy: 0.7891\n",
      "Epoch 44/100\n",
      "28/28 - 0s - loss: 0.4647 - accuracy: 0.7868\n",
      "Epoch 45/100\n",
      "28/28 - 0s - loss: 0.4612 - accuracy: 0.7812\n",
      "Epoch 46/100\n",
      "28/28 - 0s - loss: 0.4588 - accuracy: 0.7935\n",
      "Epoch 47/100\n",
      "28/28 - 0s - loss: 0.4588 - accuracy: 0.7812\n",
      "Epoch 48/100\n",
      "28/28 - 0s - loss: 0.4631 - accuracy: 0.7891\n",
      "Epoch 49/100\n",
      "28/28 - 0s - loss: 0.4591 - accuracy: 0.7868\n",
      "Epoch 50/100\n",
      "28/28 - 0s - loss: 0.4580 - accuracy: 0.7824\n",
      "Epoch 51/100\n",
      "28/28 - 0s - loss: 0.4619 - accuracy: 0.7924\n",
      "Epoch 52/100\n",
      "28/28 - 0s - loss: 0.4586 - accuracy: 0.7924\n",
      "Epoch 53/100\n",
      "28/28 - 0s - loss: 0.4630 - accuracy: 0.7835\n",
      "Epoch 54/100\n",
      "28/28 - 0s - loss: 0.4581 - accuracy: 0.7812\n",
      "Epoch 55/100\n",
      "28/28 - 0s - loss: 0.4577 - accuracy: 0.7835\n",
      "Epoch 56/100\n",
      "28/28 - 0s - loss: 0.4579 - accuracy: 0.7879\n",
      "Epoch 57/100\n",
      "28/28 - 0s - loss: 0.4566 - accuracy: 0.7846\n",
      "Epoch 58/100\n",
      "28/28 - 0s - loss: 0.4612 - accuracy: 0.7846\n",
      "Epoch 59/100\n",
      "28/28 - 0s - loss: 0.4573 - accuracy: 0.7790\n",
      "Epoch 60/100\n",
      "28/28 - 0s - loss: 0.4575 - accuracy: 0.7868\n",
      "Epoch 61/100\n",
      "28/28 - 0s - loss: 0.4581 - accuracy: 0.7879\n",
      "Epoch 62/100\n",
      "28/28 - 0s - loss: 0.4548 - accuracy: 0.7924\n",
      "Epoch 63/100\n",
      "28/28 - 0s - loss: 0.4586 - accuracy: 0.7868\n",
      "Epoch 64/100\n",
      "28/28 - 0s - loss: 0.4545 - accuracy: 0.7846\n",
      "Epoch 65/100\n",
      "28/28 - 0s - loss: 0.4569 - accuracy: 0.7902\n",
      "Epoch 66/100\n",
      "28/28 - 0s - loss: 0.4552 - accuracy: 0.7857\n",
      "Epoch 67/100\n",
      "28/28 - 0s - loss: 0.4605 - accuracy: 0.7779\n",
      "Epoch 68/100\n",
      "28/28 - 0s - loss: 0.4558 - accuracy: 0.7913\n",
      "Epoch 69/100\n",
      "28/28 - 0s - loss: 0.4547 - accuracy: 0.7902\n",
      "Epoch 70/100\n",
      "28/28 - 0s - loss: 0.4546 - accuracy: 0.7891\n",
      "Epoch 71/100\n",
      "28/28 - 0s - loss: 0.4587 - accuracy: 0.7902\n",
      "Epoch 72/100\n",
      "28/28 - 0s - loss: 0.4571 - accuracy: 0.7779\n",
      "Epoch 73/100\n",
      "28/28 - 0s - loss: 0.4544 - accuracy: 0.7980\n",
      "Epoch 74/100\n",
      "28/28 - 0s - loss: 0.4573 - accuracy: 0.7868\n",
      "Epoch 75/100\n",
      "28/28 - 0s - loss: 0.4601 - accuracy: 0.7835\n",
      "Epoch 76/100\n",
      "28/28 - 0s - loss: 0.4545 - accuracy: 0.7891\n",
      "Epoch 77/100\n",
      "28/28 - 0s - loss: 0.4525 - accuracy: 0.7913\n",
      "Epoch 78/100\n",
      "28/28 - 0s - loss: 0.4552 - accuracy: 0.7902\n",
      "Epoch 79/100\n",
      "28/28 - 0s - loss: 0.4550 - accuracy: 0.7946\n",
      "Epoch 80/100\n",
      "28/28 - 0s - loss: 0.4552 - accuracy: 0.7824\n",
      "Epoch 81/100\n",
      "28/28 - 0s - loss: 0.4543 - accuracy: 0.7824\n",
      "Epoch 82/100\n",
      "28/28 - 0s - loss: 0.4504 - accuracy: 0.7879\n",
      "Epoch 83/100\n",
      "28/28 - 0s - loss: 0.4541 - accuracy: 0.7857\n",
      "Epoch 84/100\n",
      "28/28 - 0s - loss: 0.4518 - accuracy: 0.7846\n",
      "Epoch 85/100\n",
      "28/28 - 0s - loss: 0.4529 - accuracy: 0.7902\n",
      "Epoch 86/100\n",
      "28/28 - 0s - loss: 0.4515 - accuracy: 0.7824\n",
      "Epoch 87/100\n",
      "28/28 - 0s - loss: 0.4577 - accuracy: 0.7868\n",
      "Epoch 88/100\n",
      "28/28 - 0s - loss: 0.4541 - accuracy: 0.7801\n",
      "Epoch 89/100\n",
      "28/28 - 0s - loss: 0.4594 - accuracy: 0.7879\n",
      "Epoch 90/100\n",
      "28/28 - 0s - loss: 0.4587 - accuracy: 0.7779\n",
      "Epoch 91/100\n",
      "28/28 - 0s - loss: 0.4508 - accuracy: 0.7891\n",
      "Epoch 92/100\n",
      "28/28 - 0s - loss: 0.4562 - accuracy: 0.7868\n",
      "Epoch 93/100\n",
      "28/28 - 0s - loss: 0.4531 - accuracy: 0.7835\n",
      "Epoch 94/100\n",
      "28/28 - 0s - loss: 0.4534 - accuracy: 0.7779\n",
      "Epoch 95/100\n",
      "28/28 - 0s - loss: 0.4515 - accuracy: 0.7846\n",
      "Epoch 96/100\n",
      "28/28 - 0s - loss: 0.4522 - accuracy: 0.7891\n",
      "Epoch 97/100\n",
      "28/28 - 0s - loss: 0.4521 - accuracy: 0.7868\n",
      "Epoch 98/100\n",
      "28/28 - 0s - loss: 0.4515 - accuracy: 0.7768\n",
      "Epoch 99/100\n",
      "28/28 - 0s - loss: 0.4577 - accuracy: 0.7846\n",
      "Epoch 100/100\n",
      "28/28 - 0s - loss: 0.4555 - accuracy: 0.7857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e3a86b6d88>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.4602 - accuracy: 0.7926\n",
      "Normal Neural Network - Loss: 0.46019095182418823, Accuracy: 0.7926421165466309\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.4667 - accuracy: 0.7793\n",
      "Deep Neural Network - Loss: 0.4667149782180786, Accuracy: 0.7792642116546631\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1195, 1)\n",
      "(1195, 1)\n"
     ]
    }
   ],
   "source": [
    "features = data[[\"Critic_Score\", \"User_Score\", \"PlayScore\", \"GameScore\", \"CriticScore\", \"TopSellers\"]]\n",
    "\n",
    "X = features['CriticScore'].values.reshape(-1, 1)\n",
    "y = features['TopSellers'].values.reshape(-1, 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a kmeans model using k = 12\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=12)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Use the data to predict the clusters\n",
    "# save the predictions as `predicted_clusters`\n",
    "predicted_clusters = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
